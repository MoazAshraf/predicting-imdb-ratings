{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cgCpIyJuT1Zb"
   },
   "source": [
    "## Shortlist Promising Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook assumes the data has been split into a training and a test set. If not, run get_data.ipynb first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HTOZvrk8Ye-X"
   },
   "source": [
    "1. Try these models:\n",
    "  - Linear Regression\n",
    "  - Random Forest Regressor\n",
    "  - Dense Neural Network\n",
    "  - Linear SVR\n",
    "2. Measure and compare their performance on RMSE (compare means and standard deviations of RMSE for different models as well)\n",
    "3. Make a quick round of feature selection and engineering:\n",
    "  - Try transforming variables to normal distributions\n",
    "  - Try removing unimportant features\n",
    "  - Try adding polynomial features\n",
    "4. Perform one or two more quick iterations of the five previous steps.\n",
    "5. Shortlist the top three to five most promising models, preferring models that\n",
    "make different types of errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "TRAINING_FILEPATH = 'data/training_set.csv'\n",
    "TEST_FILEPATH = 'data/test_set.csv'\n",
    "\n",
    "training_set = pd.read_csv(TRAINING_FILEPATH, index_col='index')\n",
    "test_set = pd.read_csv(TEST_FILEPATH, index_col='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_utils import separate_features_targets, FeaturePreprocessor\n",
    "\n",
    "train_X, train_y = separate_features_targets(training_set)\n",
    "\n",
    "# preprocess training features: power transform\n",
    "feature_preprocessor = FeaturePreprocessor(add_combinations=True, powertransform_num=True, onehot_type=True)\n",
    "train_X = feature_preprocessor.fit_transform(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rTq8z67lWNxq",
    "outputId": "a9ab2413-b5f3-4273-bd42-69f3ddbf27f3"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1.1203423450376466"
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "# the baseline RMSE is the standard deviation of the targets\n",
    "train_y.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5_mpHbDOT3vY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def cross_val_rmse(model, X, y, cv=5, random_state=None, model_name=None):\n",
    "    \"\"\"\n",
    "    Using K-fold cross validation, this function evaluates root mean squared error on training folds and validation folds\n",
    "    \"\"\"\n",
    "\n",
    "    # make sure X and y are numpy arrays for slicing later\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # split data into folds\n",
    "    kf = KFold(n_splits=cv, shuffle=False, random_state=random_state)\n",
    "    fold_indices = kf.split(X)\n",
    "\n",
    "    rmse_list = []\n",
    "    for indices in fold_indices:\n",
    "        train_indices = indices[0]\n",
    "        val_indices = indices[1]\n",
    "        \n",
    "        # train the model on the training folds\n",
    "        model.fit(X[train_indices], y[train_indices])\n",
    "\n",
    "        # evaluate the model on all folds\n",
    "        y_pred = model.predict(X)\n",
    "        train_rmse = np.sqrt(mean_squared_error(y[train_indices], y_pred[train_indices]))\n",
    "        val_rmse = np.sqrt(mean_squared_error(y[val_indices], y_pred[val_indices]))\n",
    "        rmse_list.append([train_rmse, val_rmse])\n",
    "    \n",
    "    # create a data frame\n",
    "    index = ['train', 'val']\n",
    "    if model_name is not None:\n",
    "        for i in range(len(index)):\n",
    "            index[i] = f\"{model_name} {index[i]}\"\n",
    "    df = pd.DataFrame(np.array(rmse_list).T, index=index, columns=[\"fold \" + str(i) for i in range(cv)])\n",
    "    \n",
    "    # compute mean and standard deviation\n",
    "    df_mean = df.mean(axis=1)\n",
    "    df_std = df.std(axis=1)\n",
    "    df['mean'] = df_mean\n",
    "    df['std'] = df_std\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vv8ClUkjf0tN"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                  fold 0    fold 1    fold 2    fold 3    fold 4      mean  \\\nbaseline train  1.123358  1.121115  1.114294  1.119928  1.122722  1.120283   \nbaseline val    1.107938  1.116999  1.143970  1.121741  1.110553  1.120240   \n\n                     std  \nbaseline train  0.003609  \nbaseline val    0.014327  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fold 0</th>\n      <th>fold 1</th>\n      <th>fold 2</th>\n      <th>fold 3</th>\n      <th>fold 4</th>\n      <th>mean</th>\n      <th>std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>baseline train</th>\n      <td>1.123358</td>\n      <td>1.121115</td>\n      <td>1.114294</td>\n      <td>1.119928</td>\n      <td>1.122722</td>\n      <td>1.120283</td>\n      <td>0.003609</td>\n    </tr>\n    <tr>\n      <th>baseline val</th>\n      <td>1.107938</td>\n      <td>1.116999</td>\n      <td>1.143970</td>\n      <td>1.121741</td>\n      <td>1.110553</td>\n      <td>1.120240</td>\n      <td>0.014327</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "baseline_model = DummyRegressor(strategy='mean')\n",
    "baseline_errors = cross_val_rmse(baseline_model, train_X, train_y, cv=5, random_state=42, model_name='baseline')\n",
    "display(baseline_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ru-7KyWcjZuf"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                fold 0    fold 1    fold 2    fold 3    fold 4      mean  \\\nlinreg train  0.893267  0.896926  0.889980  0.890549  0.894051  0.892955   \nlinreg val    0.897161  0.881527  0.910644  0.908679  0.894478  0.898498   \n\n                   std  \nlinreg train  0.002815  \nlinreg val    0.011802  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fold 0</th>\n      <th>fold 1</th>\n      <th>fold 2</th>\n      <th>fold 3</th>\n      <th>fold 4</th>\n      <th>mean</th>\n      <th>std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>linreg train</th>\n      <td>0.893267</td>\n      <td>0.896926</td>\n      <td>0.889980</td>\n      <td>0.890549</td>\n      <td>0.894051</td>\n      <td>0.892955</td>\n      <td>0.002815</td>\n    </tr>\n    <tr>\n      <th>linreg val</th>\n      <td>0.897161</td>\n      <td>0.881527</td>\n      <td>0.910644</td>\n      <td>0.908679</td>\n      <td>0.894478</td>\n      <td>0.898498</td>\n      <td>0.011802</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linreg_model = LinearRegression()\n",
    "linreg_errors = cross_val_rmse(linreg_model, train_X, train_y, cv=5, random_state=42, model_name='linreg')\n",
    "display(linreg_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SUv59CtFnpHo"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                   fold 0    fold 1    fold 2    fold 3    fold 4      mean  \\\nforestreg train  0.351510  0.357484  0.358066  0.358803  0.352321  0.355637   \nforestreg val    0.853699  0.833393  0.842670  0.842541  0.818561  0.838173   \n\n                      std  \nforestreg train  0.003441  \nforestreg val    0.013113  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fold 0</th>\n      <th>fold 1</th>\n      <th>fold 2</th>\n      <th>fold 3</th>\n      <th>fold 4</th>\n      <th>mean</th>\n      <th>std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>forestreg train</th>\n      <td>0.351510</td>\n      <td>0.357484</td>\n      <td>0.358066</td>\n      <td>0.358803</td>\n      <td>0.352321</td>\n      <td>0.355637</td>\n      <td>0.003441</td>\n    </tr>\n    <tr>\n      <th>forestreg val</th>\n      <td>0.853699</td>\n      <td>0.833393</td>\n      <td>0.842670</td>\n      <td>0.842541</td>\n      <td>0.818561</td>\n      <td>0.838173</td>\n      <td>0.013113</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forestreg_model = RandomForestRegressor()\n",
    "forestreg_errors = cross_val_rmse(forestreg_model, train_X, train_y, cv=5, random_state=42, model_name='forestreg')\n",
    "display(forestreg_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DYF17CVpjnTm"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                fold 0    fold 1    fold 2    fold 3    fold 4      mean  \\\nlinsvr train  0.906789  0.912054  0.903541  0.903642  0.908154  0.906836   \nlinsvr val    0.908406  0.893704  0.923566  0.921239  0.904131  0.910209   \n\n                   std  \nlinsvr train  0.003536  \nlinsvr val    0.012376  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fold 0</th>\n      <th>fold 1</th>\n      <th>fold 2</th>\n      <th>fold 3</th>\n      <th>fold 4</th>\n      <th>mean</th>\n      <th>std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>linsvr train</th>\n      <td>0.906789</td>\n      <td>0.912054</td>\n      <td>0.903541</td>\n      <td>0.903642</td>\n      <td>0.908154</td>\n      <td>0.906836</td>\n      <td>0.003536</td>\n    </tr>\n    <tr>\n      <th>linsvr val</th>\n      <td>0.908406</td>\n      <td>0.893704</td>\n      <td>0.923566</td>\n      <td>0.921239</td>\n      <td>0.904131</td>\n      <td>0.910209</td>\n      <td>0.012376</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "linsvr_model = LinearSVR(max_iter=100000)\n",
    "linsvr_errors = cross_val_rmse(linsvr_model, train_X, train_y, cv=5, random_state=42, model_name='linsvr')\n",
    "display(linsvr_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0m_pQSHJj23c",
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "=========] - 0s 16us/step - loss: 0.5981\nEpoch 70/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5960\nEpoch 71/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5943\nEpoch 72/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5939\nEpoch 73/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5925\nEpoch 74/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5929\nEpoch 75/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5890\nEpoch 76/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5904\nEpoch 77/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5895\nEpoch 78/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5885\nEpoch 79/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5892\nEpoch 80/150\n8672/8672 [==============================] - 0s 15us/step - loss: 0.5863\nEpoch 81/150\n8672/8672 [==============================] - 0s 15us/step - loss: 0.5885\nEpoch 82/150\n8672/8672 [==============================] - 0s 15us/step - loss: 0.5875\nEpoch 83/150\n8672/8672 [==============================] - 0s 15us/step - loss: 0.5860\nEpoch 84/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5847\nEpoch 85/150\n8672/8672 [==============================] - 0s 15us/step - loss: 0.5841\nEpoch 86/150\n8672/8672 [==============================] - 0s 15us/step - loss: 0.5822\nEpoch 87/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5818\nEpoch 88/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5832\nEpoch 89/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5780\nEpoch 90/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5785\nEpoch 91/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5795\nEpoch 92/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5797\nEpoch 93/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5799\nEpoch 94/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5783\nEpoch 95/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5744\nEpoch 96/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5767\nEpoch 97/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5768\nEpoch 98/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5749\nEpoch 99/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5737\nEpoch 100/150\n8672/8672 [==============================] - 0s 15us/step - loss: 0.5756\nEpoch 101/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5739\nEpoch 102/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5725\nEpoch 103/150\n8672/8672 [==============================] - 0s 15us/step - loss: 0.5748\nEpoch 104/150\n8672/8672 [==============================] - 0s 15us/step - loss: 0.5725\nEpoch 105/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5706\nEpoch 106/150\n8672/8672 [==============================] - 0s 15us/step - loss: 0.5703\nEpoch 107/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5721\nEpoch 108/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5686\nEpoch 109/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5688\nEpoch 110/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5686\nEpoch 111/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5681\nEpoch 112/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5677\nEpoch 113/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5664\nEpoch 114/150\n8672/8672 [==============================] - 0s 24us/step - loss: 0.5678\nEpoch 115/150\n8672/8672 [==============================] - 0s 20us/step - loss: 0.5688\nEpoch 116/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5661\nEpoch 117/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.5667\nEpoch 118/150\n8672/8672 [==============================] - 0s 20us/step - loss: 0.5629\nEpoch 119/150\n8672/8672 [==============================] - 0s 21us/step - loss: 0.5651\nEpoch 120/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5633\nEpoch 121/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5635\nEpoch 122/150\n8672/8672 [==============================] - 0s 15us/step - loss: 0.5643\nEpoch 123/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.5639\nEpoch 124/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5602\nEpoch 125/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5652\nEpoch 126/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5591\nEpoch 127/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5588\nEpoch 128/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5594\nEpoch 129/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5569\nEpoch 130/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5604\nEpoch 131/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5589\nEpoch 132/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5561\nEpoch 133/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5582\nEpoch 134/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5560\nEpoch 135/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5580\nEpoch 136/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5552\nEpoch 137/150\n8672/8672 [==============================] - 0s 20us/step - loss: 0.5575\nEpoch 138/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5536\nEpoch 139/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5563\nEpoch 140/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5538\nEpoch 141/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5521\nEpoch 142/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.5534\nEpoch 143/150\n8672/8672 [==============================] - 0s 20us/step - loss: 0.5515\nEpoch 144/150\n8672/8672 [==============================] - 0s 20us/step - loss: 0.5535\nEpoch 145/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5513\nEpoch 146/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5535\nEpoch 147/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5511\nEpoch 148/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5524\nEpoch 149/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5492\nEpoch 150/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5521\nEpoch 1/150\n8672/8672 [==============================] - 0s 29us/step - loss: 2.0168\nEpoch 2/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.8949\nEpoch 3/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.8260\nEpoch 4/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.7931\nEpoch 5/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.7709\nEpoch 6/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.7528\nEpoch 7/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.7432\nEpoch 8/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.7324\nEpoch 9/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.7221\nEpoch 10/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.7128\nEpoch 11/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.7076\nEpoch 12/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6990\nEpoch 13/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6945\nEpoch 14/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6887\nEpoch 15/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6827\nEpoch 16/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6783\nEpoch 17/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6766\nEpoch 18/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6730\nEpoch 19/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6701\nEpoch 20/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6656\nEpoch 21/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6630\nEpoch 22/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6598\nEpoch 23/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6591\nEpoch 24/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6518\nEpoch 25/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6502\nEpoch 26/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6499\nEpoch 27/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6469\nEpoch 28/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6456\nEpoch 29/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6402\nEpoch 30/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6401\nEpoch 31/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6399\nEpoch 32/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6376\nEpoch 33/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6341\nEpoch 34/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6345\nEpoch 35/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6315\nEpoch 36/150\n8672/8672 [==============================] - 0s 15us/step - loss: 0.6296\nEpoch 37/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6288\nEpoch 38/150\n8672/8672 [==============================] - 0s 15us/step - loss: 0.6266\nEpoch 39/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6298\nEpoch 40/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6224\nEpoch 41/150\n8672/8672 [==============================] - 0s 15us/step - loss: 0.6259\nEpoch 42/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6204\nEpoch 43/150\n8672/8672 [==============================] - 0s 15us/step - loss: 0.6209\nEpoch 44/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6210\nEpoch 45/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6211\nEpoch 46/150\n8672/8672 [==============================] - 0s 15us/step - loss: 0.6177\nEpoch 47/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6143\nEpoch 48/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6164\nEpoch 49/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6125\nEpoch 50/150\n8672/8672 [==============================] - 0s 15us/step - loss: 0.6134\nEpoch 51/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6105\nEpoch 52/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6109\nEpoch 53/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6078\nEpoch 54/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6094\nEpoch 55/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6070\nEpoch 56/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6058\nEpoch 57/150\n8672/8672 [==============================] - 0s 15us/step - loss: 0.6064\nEpoch 58/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6053\nEpoch 59/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6021\nEpoch 60/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6047\nEpoch 61/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6053\nEpoch 62/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6015\nEpoch 63/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6010\nEpoch 64/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5993\nEpoch 65/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5983\nEpoch 66/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6029\nEpoch 67/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5962\nEpoch 68/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5968\nEpoch 69/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5967\nEpoch 70/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5939\nEpoch 71/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5965\nEpoch 72/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5939\nEpoch 73/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5945\nEpoch 74/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5920\nEpoch 75/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5945\nEpoch 76/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5941\nEpoch 77/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5898\nEpoch 78/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5911\nEpoch 79/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5890\nEpoch 80/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5896\nEpoch 81/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5877\nEpoch 82/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5861\nEpoch 83/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5873\nEpoch 84/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5861\nEpoch 85/150\n8672/8672 [==============================] - 0s 15us/step - loss: 0.5869\nEpoch 86/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5830\nEpoch 87/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5852\nEpoch 88/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5838\nEpoch 89/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5832\nEpoch 90/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5846\nEpoch 91/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5799\nEpoch 92/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5829\nEpoch 93/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5800\nEpoch 94/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5816\nEpoch 95/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5807\nEpoch 96/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5789\nEpoch 97/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5787\nEpoch 98/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5773\nEpoch 99/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5769\nEpoch 100/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5773\nEpoch 101/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5797\nEpoch 102/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5770\nEpoch 103/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5773\nEpoch 104/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5744\nEpoch 105/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5781\nEpoch 106/150\n8672/8672 [==============================] - 0s 20us/step - loss: 0.5713\nEpoch 107/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5734\nEpoch 108/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5734\nEpoch 109/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5709\nEpoch 110/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5726\nEpoch 111/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5729\nEpoch 112/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5694\nEpoch 113/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5707\nEpoch 114/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5694\nEpoch 115/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5713\nEpoch 116/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5681\nEpoch 117/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5688\nEpoch 118/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5688\nEpoch 119/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5666\nEpoch 120/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5684\nEpoch 121/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5695\nEpoch 122/150\n8672/8672 [==============================] - 0s 21us/step - loss: 0.5664\nEpoch 123/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5651\nEpoch 124/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5671\nEpoch 125/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5660\nEpoch 126/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5666\nEpoch 127/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5646\nEpoch 128/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5646\nEpoch 129/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5647\nEpoch 130/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5647\nEpoch 131/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5633\nEpoch 132/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5623\nEpoch 133/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5613\nEpoch 134/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5620\nEpoch 135/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5624\nEpoch 136/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5608\nEpoch 137/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5602\nEpoch 138/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5604\nEpoch 139/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5602\nEpoch 140/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5602\nEpoch 141/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5606\nEpoch 142/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5609\nEpoch 143/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5574\nEpoch 144/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5592\nEpoch 145/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5566\nEpoch 146/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5583\nEpoch 147/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5547\nEpoch 148/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5578\nEpoch 149/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5551\nEpoch 150/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5568\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                   fold 0    fold 1    fold 2    fold 3    fold 4      mean  \\\nneuralnet train  0.730743  0.734475  0.736975  0.747654  0.733245  0.736619   \nneuralnet val    0.820865  0.809628  0.809639  0.820308  0.813770  0.814842   \n\n                      std  \nneuralnet train  0.006565  \nneuralnet val    0.005513  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fold 0</th>\n      <th>fold 1</th>\n      <th>fold 2</th>\n      <th>fold 3</th>\n      <th>fold 4</th>\n      <th>mean</th>\n      <th>std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>neuralnet train</th>\n      <td>0.730743</td>\n      <td>0.734475</td>\n      <td>0.736975</td>\n      <td>0.747654</td>\n      <td>0.733245</td>\n      <td>0.736619</td>\n      <td>0.006565</td>\n    </tr>\n    <tr>\n      <th>neuralnet val</th>\n      <td>0.820865</td>\n      <td>0.809628</td>\n      <td>0.809639</td>\n      <td>0.820308</td>\n      <td>0.813770</td>\n      <td>0.814842</td>\n      <td>0.005513</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "def create_neuralnet_model(input_shape):\n",
    "    def create_model():\n",
    "        model = Sequential([\n",
    "                            Dense(32, input_shape=input_shape, activation='relu'),\n",
    "                            Dense(1)\n",
    "                ])\n",
    "        model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "        return model\n",
    "\n",
    "    # wrap the neural network model to be used by scikit-learn\n",
    "    neuralnet_model = KerasRegressor(create_model, epochs=150)\n",
    "    return neuralnet_model\n",
    "\n",
    "neuralnet_model = create_neuralnet_model(train_X.shape[1:])\n",
    "neuralnet_errors = cross_val_rmse(neuralnet_model, train_X, train_y, cv=5, random_state=42, model_name='neuralnet')\n",
    "display(neuralnet_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SkPo0DwQu_f9"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                   fold 0    fold 1    fold 2    fold 3    fold 4      mean  \\\nbaseline train   1.123358  1.121115  1.114294  1.119928  1.122722  1.120283   \nbaseline val     1.107938  1.116999  1.143970  1.121741  1.110553  1.120240   \nlinreg train     0.893267  0.896926  0.889980  0.890549  0.894051  0.892955   \nlinreg val       0.897161  0.881527  0.910644  0.908679  0.894478  0.898498   \nforestreg train  0.351510  0.357484  0.358066  0.358803  0.352321  0.355637   \nforestreg val    0.853699  0.833393  0.842670  0.842541  0.818561  0.838173   \nlinsvr train     0.906789  0.912054  0.903541  0.903642  0.908154  0.906836   \nlinsvr val       0.908406  0.893704  0.923566  0.921239  0.904131  0.910209   \nneuralnet train  0.730743  0.734475  0.736975  0.747654  0.733245  0.736619   \nneuralnet val    0.820865  0.809628  0.809639  0.820308  0.813770  0.814842   \n\n                      std  \nbaseline train   0.003609  \nbaseline val     0.014327  \nlinreg train     0.002815  \nlinreg val       0.011802  \nforestreg train  0.003441  \nforestreg val    0.013113  \nlinsvr train     0.003536  \nlinsvr val       0.012376  \nneuralnet train  0.006565  \nneuralnet val    0.005513  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fold 0</th>\n      <th>fold 1</th>\n      <th>fold 2</th>\n      <th>fold 3</th>\n      <th>fold 4</th>\n      <th>mean</th>\n      <th>std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>baseline train</th>\n      <td>1.123358</td>\n      <td>1.121115</td>\n      <td>1.114294</td>\n      <td>1.119928</td>\n      <td>1.122722</td>\n      <td>1.120283</td>\n      <td>0.003609</td>\n    </tr>\n    <tr>\n      <th>baseline val</th>\n      <td>1.107938</td>\n      <td>1.116999</td>\n      <td>1.143970</td>\n      <td>1.121741</td>\n      <td>1.110553</td>\n      <td>1.120240</td>\n      <td>0.014327</td>\n    </tr>\n    <tr>\n      <th>linreg train</th>\n      <td>0.893267</td>\n      <td>0.896926</td>\n      <td>0.889980</td>\n      <td>0.890549</td>\n      <td>0.894051</td>\n      <td>0.892955</td>\n      <td>0.002815</td>\n    </tr>\n    <tr>\n      <th>linreg val</th>\n      <td>0.897161</td>\n      <td>0.881527</td>\n      <td>0.910644</td>\n      <td>0.908679</td>\n      <td>0.894478</td>\n      <td>0.898498</td>\n      <td>0.011802</td>\n    </tr>\n    <tr>\n      <th>forestreg train</th>\n      <td>0.351510</td>\n      <td>0.357484</td>\n      <td>0.358066</td>\n      <td>0.358803</td>\n      <td>0.352321</td>\n      <td>0.355637</td>\n      <td>0.003441</td>\n    </tr>\n    <tr>\n      <th>forestreg val</th>\n      <td>0.853699</td>\n      <td>0.833393</td>\n      <td>0.842670</td>\n      <td>0.842541</td>\n      <td>0.818561</td>\n      <td>0.838173</td>\n      <td>0.013113</td>\n    </tr>\n    <tr>\n      <th>linsvr train</th>\n      <td>0.906789</td>\n      <td>0.912054</td>\n      <td>0.903541</td>\n      <td>0.903642</td>\n      <td>0.908154</td>\n      <td>0.906836</td>\n      <td>0.003536</td>\n    </tr>\n    <tr>\n      <th>linsvr val</th>\n      <td>0.908406</td>\n      <td>0.893704</td>\n      <td>0.923566</td>\n      <td>0.921239</td>\n      <td>0.904131</td>\n      <td>0.910209</td>\n      <td>0.012376</td>\n    </tr>\n    <tr>\n      <th>neuralnet train</th>\n      <td>0.730743</td>\n      <td>0.734475</td>\n      <td>0.736975</td>\n      <td>0.747654</td>\n      <td>0.733245</td>\n      <td>0.736619</td>\n      <td>0.006565</td>\n    </tr>\n    <tr>\n      <th>neuralnet val</th>\n      <td>0.820865</td>\n      <td>0.809628</td>\n      <td>0.809639</td>\n      <td>0.820308</td>\n      <td>0.813770</td>\n      <td>0.814842</td>\n      <td>0.005513</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "power_tr_model_errors = pd.concat([baseline_errors, linreg_errors, forestreg_errors, linsvr_errors, neuralnet_errors])\n",
    "power_tr_model_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(train_X, train_y):\n",
    "    baseline_errors = cross_val_rmse(baseline_model, train_X, train_y, cv=5, model_name='baseline')\n",
    "    linreg_errors = cross_val_rmse(linreg_model, train_X, train_y, cv=5, model_name='linreg')\n",
    "    forestreg_errors = cross_val_rmse(forestreg_model, train_X, train_y, cv=5, model_name='forestreg')\n",
    "    linsvr_errors = cross_val_rmse(linsvr_model, train_X, train_y, cv=5, model_name='linsvr')\n",
    "\n",
    "    neuralnet_model = create_neuralnet_model(train_X.shape[1:])\n",
    "    neuralnet_errors = cross_val_rmse(neuralnet_model, train_X, train_y, cv=5, model_name='neuralnet')\n",
    "    \n",
    "    return pd.concat([baseline_errors, linreg_errors, forestreg_errors, linsvr_errors, neuralnet_errors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3_kNtXOirf8Q"
   },
   "outputs": [],
   "source": [
    "train_X, train_y = separate_features_targets(training_set)\n",
    "\n",
    "# preprocess training features (standardization)\n",
    "feature_preprocessor_std = FeaturePreprocessor(add_combinations=True, std_scale_num=True, onehot_type=True)\n",
    "train_X_std = feature_preprocessor_std.fit_transform(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "j_pXrqpCv6ei",
    "outputId": "c4975eca-0bf3-4b51-e1c5-dd83c13821fd",
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "=========] - 0s 18us/step - loss: 0.6361\nEpoch 70/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6441\nEpoch 71/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6355\nEpoch 72/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6339\nEpoch 73/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6377\nEpoch 74/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6360\nEpoch 75/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6388\nEpoch 76/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6333\nEpoch 77/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6280\nEpoch 78/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6295\nEpoch 79/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6291\nEpoch 80/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6343\nEpoch 81/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6273\nEpoch 82/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6283\nEpoch 83/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6277\nEpoch 84/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6260\nEpoch 85/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6257\nEpoch 86/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6227\nEpoch 87/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6248\nEpoch 88/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6568\nEpoch 89/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6229\nEpoch 90/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6223\nEpoch 91/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6220\nEpoch 92/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6207\nEpoch 93/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6193\nEpoch 94/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6279\nEpoch 95/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6253\nEpoch 96/150\n8672/8672 [==============================] - 0s 20us/step - loss: 0.6177\nEpoch 97/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6193\nEpoch 98/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6163\nEpoch 99/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6176\nEpoch 100/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6236\nEpoch 101/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6165\nEpoch 102/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6184\nEpoch 103/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6174\nEpoch 104/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6140\nEpoch 105/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6091\nEpoch 106/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6129\nEpoch 107/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6114\nEpoch 108/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6199\nEpoch 109/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6222\nEpoch 110/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6104\nEpoch 111/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6088\nEpoch 112/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6057\nEpoch 113/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6183\nEpoch 114/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6080\nEpoch 115/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6067\nEpoch 116/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6048\nEpoch 117/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6090\nEpoch 118/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6063\nEpoch 119/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6100\nEpoch 120/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6082\nEpoch 121/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6046\nEpoch 122/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6027\nEpoch 123/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6026\nEpoch 124/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6078\nEpoch 125/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6053\nEpoch 126/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6087\nEpoch 127/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6046\nEpoch 128/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6051\nEpoch 129/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6002\nEpoch 130/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5971\nEpoch 131/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5997\nEpoch 132/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6045\nEpoch 133/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6000\nEpoch 134/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5985\nEpoch 135/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5997\nEpoch 136/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6014\nEpoch 137/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5978\nEpoch 138/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5979\nEpoch 139/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5982\nEpoch 140/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5984\nEpoch 141/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6010\nEpoch 142/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5974\nEpoch 143/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5955\nEpoch 144/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6066\nEpoch 145/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.5942\nEpoch 146/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5943\nEpoch 147/150\n8672/8672 [==============================] - 0s 20us/step - loss: 0.5928\nEpoch 148/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5942\nEpoch 149/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5886\nEpoch 150/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5932\nEpoch 1/150\n8672/8672 [==============================] - 0s 36us/step - loss: 2.1251\nEpoch 2/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.9289\nEpoch 3/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.8713\nEpoch 4/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.8226\nEpoch 5/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.8039\nEpoch 6/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.7789\nEpoch 7/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.7845\nEpoch 8/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.7620\nEpoch 9/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.7666\nEpoch 10/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.7512\nEpoch 11/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.7421\nEpoch 12/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.7490\nEpoch 13/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.7370\nEpoch 14/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.7316\nEpoch 15/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.7468\nEpoch 16/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.7273\nEpoch 17/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.7232\nEpoch 18/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.7174\nEpoch 19/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.7095\nEpoch 20/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.7059\nEpoch 21/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.7488\nEpoch 22/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.7033\nEpoch 23/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6998\nEpoch 24/150\n8672/8672 [==============================] - 0s 20us/step - loss: 0.6974\nEpoch 25/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.7673\nEpoch 26/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.7038\nEpoch 27/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.7025\nEpoch 28/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6936\nEpoch 29/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6893\nEpoch 30/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6842\nEpoch 31/150\n8672/8672 [==============================] - 0s 20us/step - loss: 0.6830\nEpoch 32/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6938\nEpoch 33/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.7233\nEpoch 34/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6803\nEpoch 35/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6791\nEpoch 36/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6831\nEpoch 37/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6761\nEpoch 38/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6706\nEpoch 39/150\n8672/8672 [==============================] - 0s 20us/step - loss: 0.6695\nEpoch 40/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6716\nEpoch 41/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6674\nEpoch 42/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6699\nEpoch 43/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6622\nEpoch 44/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6641\nEpoch 45/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6858\nEpoch 46/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6665\nEpoch 47/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6669\nEpoch 48/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6565\nEpoch 49/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6579\nEpoch 50/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.7447\nEpoch 51/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.7580\nEpoch 52/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6681\nEpoch 53/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6592\nEpoch 54/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6592\nEpoch 55/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6514\nEpoch 56/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6594\nEpoch 57/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6522\nEpoch 58/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6544\nEpoch 59/150\n8672/8672 [==============================] - 0s 22us/step - loss: 0.6523\nEpoch 60/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6500\nEpoch 61/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6461\nEpoch 62/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6484\nEpoch 63/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6500\nEpoch 64/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6408\nEpoch 65/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6429\nEpoch 66/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6406\nEpoch 67/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6406\nEpoch 68/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6438\nEpoch 69/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6365\nEpoch 70/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6381\nEpoch 71/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6501\nEpoch 72/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6383\nEpoch 73/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6311\nEpoch 74/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6656\nEpoch 75/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6307\nEpoch 76/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6289\nEpoch 77/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6533\nEpoch 78/150\n8672/8672 [==============================] - 0s 21us/step - loss: 0.6440\nEpoch 79/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6376\nEpoch 80/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6266\nEpoch 81/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6285\nEpoch 82/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6248\nEpoch 83/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6320\nEpoch 84/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6398\nEpoch 85/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6250\nEpoch 86/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6242\nEpoch 87/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6255\nEpoch 88/150\n8672/8672 [==============================] - 0s 21us/step - loss: 0.6239\nEpoch 89/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6241\nEpoch 90/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6280\nEpoch 91/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6218\nEpoch 92/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6396\nEpoch 93/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6294\nEpoch 94/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6203\nEpoch 95/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6184\nEpoch 96/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6192\nEpoch 97/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6212\nEpoch 98/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6151\nEpoch 99/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6180\nEpoch 100/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6239\nEpoch 101/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6151\nEpoch 102/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6210\nEpoch 103/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6173\nEpoch 104/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.6246\nEpoch 105/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6119\nEpoch 106/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6206\nEpoch 107/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6140\nEpoch 108/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6110\nEpoch 109/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6107\nEpoch 110/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6140\nEpoch 111/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6089\nEpoch 112/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6042\nEpoch 113/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6082\nEpoch 114/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6067\nEpoch 115/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6489\nEpoch 116/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6115\nEpoch 117/150\n8672/8672 [==============================] - 0s 21us/step - loss: 0.6098\nEpoch 118/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6073\nEpoch 119/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6183\nEpoch 120/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6289\nEpoch 121/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6063\nEpoch 122/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6118\nEpoch 123/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6085\nEpoch 124/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6065\nEpoch 125/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6079\nEpoch 126/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6113\nEpoch 127/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6037\nEpoch 128/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6405\nEpoch 129/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6181\nEpoch 130/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6098\nEpoch 131/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6027\nEpoch 132/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6133\nEpoch 133/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6047\nEpoch 134/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6001\nEpoch 135/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6023\nEpoch 136/150\n8672/8672 [==============================] - 0s 20us/step - loss: 0.6048\nEpoch 137/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6119\nEpoch 138/150\n8672/8672 [==============================] - 0s 20us/step - loss: 0.6261\nEpoch 139/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.5992\nEpoch 140/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6050\nEpoch 141/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6066\nEpoch 142/150\n8672/8672 [==============================] - 0s 21us/step - loss: 0.6033\nEpoch 143/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6002\nEpoch 144/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6001\nEpoch 145/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5983\nEpoch 146/150\n8672/8672 [==============================] - 0s 20us/step - loss: 0.6044\nEpoch 147/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6018\nEpoch 148/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6003\nEpoch 149/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5972\nEpoch 150/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5997\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                   fold 0    fold 1    fold 2    fold 3    fold 4      mean  \\\nbaseline train   1.123358  1.121115  1.114294  1.119928  1.122722  1.120283   \nbaseline val     1.107938  1.116999  1.143970  1.121741  1.110553  1.120240   \nlinreg train     0.913938  0.915948  0.906405  0.909648  0.916653  0.912518   \nlinreg val       0.909653  0.900677  0.939456  0.929410  0.911433  0.918126   \nforestreg train  0.352948  0.348856  0.356390  0.352738  0.354742  0.353135   \nforestreg val    0.839054  0.823235  0.850745  0.842143  0.827498  0.836535   \nlinsvr train     0.931366  0.933233  0.923040  0.925438  0.930060  0.928627   \nlinsvr val       0.922163  0.920070  0.954817  0.948644  0.918581  0.932855   \nneuralnet train  0.772485  0.787028  0.759109  0.765387  0.766973  0.770196   \nneuralnet val    0.859897  0.829562  0.858548  0.844658  0.833050  0.845143   \n\n                      std  \nbaseline train   0.003609  \nbaseline val     0.014327  \nlinreg train     0.004373  \nlinreg val       0.015838  \nforestreg train  0.002814  \nforestreg val    0.011161  \nlinsvr train     0.004247  \nlinsvr val       0.017415  \nneuralnet train  0.010547  \nneuralnet val    0.014024  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fold 0</th>\n      <th>fold 1</th>\n      <th>fold 2</th>\n      <th>fold 3</th>\n      <th>fold 4</th>\n      <th>mean</th>\n      <th>std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>baseline train</th>\n      <td>1.123358</td>\n      <td>1.121115</td>\n      <td>1.114294</td>\n      <td>1.119928</td>\n      <td>1.122722</td>\n      <td>1.120283</td>\n      <td>0.003609</td>\n    </tr>\n    <tr>\n      <th>baseline val</th>\n      <td>1.107938</td>\n      <td>1.116999</td>\n      <td>1.143970</td>\n      <td>1.121741</td>\n      <td>1.110553</td>\n      <td>1.120240</td>\n      <td>0.014327</td>\n    </tr>\n    <tr>\n      <th>linreg train</th>\n      <td>0.913938</td>\n      <td>0.915948</td>\n      <td>0.906405</td>\n      <td>0.909648</td>\n      <td>0.916653</td>\n      <td>0.912518</td>\n      <td>0.004373</td>\n    </tr>\n    <tr>\n      <th>linreg val</th>\n      <td>0.909653</td>\n      <td>0.900677</td>\n      <td>0.939456</td>\n      <td>0.929410</td>\n      <td>0.911433</td>\n      <td>0.918126</td>\n      <td>0.015838</td>\n    </tr>\n    <tr>\n      <th>forestreg train</th>\n      <td>0.352948</td>\n      <td>0.348856</td>\n      <td>0.356390</td>\n      <td>0.352738</td>\n      <td>0.354742</td>\n      <td>0.353135</td>\n      <td>0.002814</td>\n    </tr>\n    <tr>\n      <th>forestreg val</th>\n      <td>0.839054</td>\n      <td>0.823235</td>\n      <td>0.850745</td>\n      <td>0.842143</td>\n      <td>0.827498</td>\n      <td>0.836535</td>\n      <td>0.011161</td>\n    </tr>\n    <tr>\n      <th>linsvr train</th>\n      <td>0.931366</td>\n      <td>0.933233</td>\n      <td>0.923040</td>\n      <td>0.925438</td>\n      <td>0.930060</td>\n      <td>0.928627</td>\n      <td>0.004247</td>\n    </tr>\n    <tr>\n      <th>linsvr val</th>\n      <td>0.922163</td>\n      <td>0.920070</td>\n      <td>0.954817</td>\n      <td>0.948644</td>\n      <td>0.918581</td>\n      <td>0.932855</td>\n      <td>0.017415</td>\n    </tr>\n    <tr>\n      <th>neuralnet train</th>\n      <td>0.772485</td>\n      <td>0.787028</td>\n      <td>0.759109</td>\n      <td>0.765387</td>\n      <td>0.766973</td>\n      <td>0.770196</td>\n      <td>0.010547</td>\n    </tr>\n    <tr>\n      <th>neuralnet val</th>\n      <td>0.859897</td>\n      <td>0.829562</td>\n      <td>0.858548</td>\n      <td>0.844658</td>\n      <td>0.833050</td>\n      <td>0.845143</td>\n      <td>0.014024</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "source": [
    "std_errors = evaluate_models(train_X_std, train_y)\n",
    "std_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "UhAzmaTKoYYp",
    "outputId": "891c79ed-9fa3-4109-fe84-8272f84d087d"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n           max_features='auto', max_leaf_nodes=None,\n           min_impurity_decrease=0.0, min_impurity_split=None,\n           min_samples_leaf=1, min_samples_split=2,\n           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n           oob_score=False, random_state=None, verbose=0, warm_start=False)"
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "train_X, train_y = separate_features_targets(training_set)\n",
    "\n",
    "train_X = feature_preprocessor.fit_transform(train_X)\n",
    "forestreg_model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "4ruWR7baoznC",
    "outputId": "3080df9f-ec1f-4263-bd2d-cd6e1a304baa"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "               feature  importance\n0                 year    0.143466\n1          ratingCount    0.127177\n2     reviewsPerRating    0.112401\n3             duration    0.097468\n4     type_video.movie    0.070445\n5             nrOfWins    0.068954\n6      nrOfUserReviews    0.042679\n7           nrOfPhotos    0.039809\n8    winsPerNomination    0.039808\n9     nrOfNewsArticles    0.038612\n10         Documentary    0.023360\n11               Drama    0.018463\n12           nrOfGenre    0.017664\n13    totalNominations    0.014128\n14               SciFi    0.013846\n15              Comedy    0.011108\n16           Animation    0.010736\n17              Horror    0.010436\n18       type_video.tv    0.008830\n19     nrOfNominations    0.007810\n20              Family    0.007271\n21              Action    0.007215\n22           RealityTV    0.007142\n23                News    0.006897\n24           Adventure    0.006572\n25             Fantasy    0.006471\n26               Crime    0.005182\n27             Romance    0.004602\n28               Music    0.004151\n29             Musical    0.003854\n30            TalkShow    0.003842\n31            Thriller    0.003817\n32  type_video.episode    0.003424\n33             History    0.002195\n34             Mystery    0.002147\n35               Short    0.001715\n36           Biography    0.001214\n37               Sport    0.001214\n38                 War    0.001035\n39            GameShow    0.000803\n40             Western    0.000772\n41           type_game    0.000690\n42               Adult    0.000480\n43            FilmNoir    0.000094",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature</th>\n      <th>importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>year</td>\n      <td>0.143466</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ratingCount</td>\n      <td>0.127177</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>reviewsPerRating</td>\n      <td>0.112401</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>duration</td>\n      <td>0.097468</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>type_video.movie</td>\n      <td>0.070445</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>nrOfWins</td>\n      <td>0.068954</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>nrOfUserReviews</td>\n      <td>0.042679</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>nrOfPhotos</td>\n      <td>0.039809</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>winsPerNomination</td>\n      <td>0.039808</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>nrOfNewsArticles</td>\n      <td>0.038612</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Documentary</td>\n      <td>0.023360</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Drama</td>\n      <td>0.018463</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>nrOfGenre</td>\n      <td>0.017664</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>totalNominations</td>\n      <td>0.014128</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>SciFi</td>\n      <td>0.013846</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Comedy</td>\n      <td>0.011108</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Animation</td>\n      <td>0.010736</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Horror</td>\n      <td>0.010436</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>type_video.tv</td>\n      <td>0.008830</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>nrOfNominations</td>\n      <td>0.007810</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Family</td>\n      <td>0.007271</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Action</td>\n      <td>0.007215</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>RealityTV</td>\n      <td>0.007142</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>News</td>\n      <td>0.006897</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Adventure</td>\n      <td>0.006572</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Fantasy</td>\n      <td>0.006471</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Crime</td>\n      <td>0.005182</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Romance</td>\n      <td>0.004602</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Music</td>\n      <td>0.004151</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Musical</td>\n      <td>0.003854</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>TalkShow</td>\n      <td>0.003842</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>Thriller</td>\n      <td>0.003817</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>type_video.episode</td>\n      <td>0.003424</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>History</td>\n      <td>0.002195</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>Mystery</td>\n      <td>0.002147</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>Short</td>\n      <td>0.001715</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>Biography</td>\n      <td>0.001214</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>Sport</td>\n      <td>0.001214</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>War</td>\n      <td>0.001035</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>GameShow</td>\n      <td>0.000803</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>Western</td>\n      <td>0.000772</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>type_game</td>\n      <td>0.000690</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>Adult</td>\n      <td>0.000480</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>FilmNoir</td>\n      <td>0.000094</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "source": [
    "forestreg_feature_importances = pd.DataFrame({'feature': train_X.columns, 'importance': forestreg_model.feature_importances_})\n",
    "forestreg_feature_importances = forestreg_feature_importances.sort_values(by='importance', ascending=False)\n",
    "forestreg_feature_importances = forestreg_feature_importances.reset_index(drop=True)\n",
    "forestreg_feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "VijpKF9a1SiM",
    "outputId": "592441ba-d9f9-49fc-da01-c1eecf92dfc6"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['Mystery',\n 'Short',\n 'Biography',\n 'Sport',\n 'War',\n 'GameShow',\n 'Western',\n 'type_game',\n 'Adult',\n 'FilmNoir']"
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "source": [
    "least_important_features = list(forestreg_feature_importances.iloc[-10:]['feature'].values)\n",
    "least_important_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "70cpd-6nzqpB",
    "outputId": "465b443a-fe45-4e53-9ac9-1b152c64a89a"
   },
   "outputs": [],
   "source": [
    "train_X, train_y = separate_features_targets(training_set)\n",
    "\n",
    "# preprocess training features (power transform, remove least important features)\n",
    "feature_preprocessor = FeaturePreprocessor(add_combinations=True, powertransform_num=True, onehot_type=True,\n",
    "                                           drop_features=least_important_features)\n",
    "train_X = feature_preprocessor.fit_transform(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 638
    },
    "colab_type": "code",
    "id": "pM36l8Cg3i0v",
    "outputId": "2533f3fa-0c3b-4200-a129-b6fe95c5589f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 10840 entries, 11613 to 14254\nData columns (total 34 columns):\nratingCount           10840 non-null float64\nduration              10840 non-null float64\nyear                  10840 non-null float64\nnrOfWins              10840 non-null float64\nnrOfNominations       10840 non-null float64\nnrOfPhotos            10840 non-null float64\nnrOfNewsArticles      10840 non-null float64\nnrOfUserReviews       10840 non-null float64\nnrOfGenre             10840 non-null float64\ntotalNominations      10840 non-null float64\nwinsPerNomination     10840 non-null float64\nreviewsPerRating      10840 non-null float64\ntype_video.episode    10840 non-null float64\ntype_video.movie      10840 non-null float64\ntype_video.tv         10840 non-null float64\nAction                10840 non-null int64\nAdventure             10840 non-null int64\nAnimation             10840 non-null int64\nComedy                10840 non-null int64\nCrime                 10840 non-null int64\nDocumentary           10840 non-null int64\nDrama                 10840 non-null int64\nFamily                10840 non-null int64\nFantasy               10840 non-null int64\nHistory               10840 non-null int64\nHorror                10840 non-null int64\nMusic                 10840 non-null int64\nMusical               10840 non-null int64\nNews                  10840 non-null int64\nRealityTV             10840 non-null int64\nRomance               10840 non-null int64\nSciFi                 10840 non-null int64\nTalkShow              10840 non-null int64\nThriller              10840 non-null int64\ndtypes: float64(15), int64(19)\nmemory usage: 2.9 MB\n"
    }
   ],
   "source": [
    "train_X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "K2w1K7640I42",
    "outputId": "ba9f2b98-9cb7-49ac-f88d-ca510a7dfc5c",
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "=========] - 0s 17us/step - loss: 0.5939\nEpoch 70/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5929\nEpoch 71/150\n8672/8672 [==============================] - 0s 23us/step - loss: 0.5918\nEpoch 72/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5925\nEpoch 73/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5912\nEpoch 74/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.5875\nEpoch 75/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.5903\nEpoch 76/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5874\nEpoch 77/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5908\nEpoch 78/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5892\nEpoch 79/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5885\nEpoch 80/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5859\nEpoch 81/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5844\nEpoch 82/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5864\nEpoch 83/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5833\nEpoch 84/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5856\nEpoch 85/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5835\nEpoch 86/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5810\nEpoch 87/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5832\nEpoch 88/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5813\nEpoch 89/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5835\nEpoch 90/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5794\nEpoch 91/150\n8672/8672 [==============================] - 0s 16us/step - loss: 0.5823\nEpoch 92/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5781\nEpoch 93/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5785\nEpoch 94/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5787\nEpoch 95/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5801\nEpoch 96/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5797\nEpoch 97/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5793\nEpoch 98/150\n8672/8672 [==============================] - 0s 20us/step - loss: 0.5768\nEpoch 99/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5780\nEpoch 100/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5758\nEpoch 101/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5755\nEpoch 102/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5736\nEpoch 103/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5745\nEpoch 104/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5748\nEpoch 105/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5732\nEpoch 106/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5725\nEpoch 107/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5730\nEpoch 108/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5733\nEpoch 109/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5723\nEpoch 110/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5705\nEpoch 111/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5736\nEpoch 112/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5703\nEpoch 113/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5670\nEpoch 114/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5698\nEpoch 115/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5715\nEpoch 116/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.5686\nEpoch 117/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5665\nEpoch 118/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5685\nEpoch 119/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5670\nEpoch 120/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5670\nEpoch 121/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5665\nEpoch 122/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5640\nEpoch 123/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5670\nEpoch 124/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5648\nEpoch 125/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5650\nEpoch 126/150\n8672/8672 [==============================] - 0s 20us/step - loss: 0.5650\nEpoch 127/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5652\nEpoch 128/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5645\nEpoch 129/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.5629\nEpoch 130/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5610\nEpoch 131/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5641\nEpoch 132/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5607\nEpoch 133/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5620\nEpoch 134/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5639\nEpoch 135/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5627\nEpoch 136/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5588\nEpoch 137/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5632\nEpoch 138/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5616\nEpoch 139/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5605\nEpoch 140/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5593\nEpoch 141/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5603\nEpoch 142/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5602\nEpoch 143/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5579\nEpoch 144/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5588\nEpoch 145/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5585\nEpoch 146/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5589\nEpoch 147/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5594\nEpoch 148/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5561\nEpoch 149/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5577\nEpoch 150/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5579\nEpoch 1/150\n8672/8672 [==============================] - 0s 47us/step - loss: 1.9765\nEpoch 2/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.8714\nEpoch 3/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.8223\nEpoch 4/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.7971\nEpoch 5/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.7804\nEpoch 6/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.7668\nEpoch 7/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.7579\nEpoch 8/150\n8672/8672 [==============================] - 0s 21us/step - loss: 0.7446\nEpoch 9/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.7374\nEpoch 10/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.7300\nEpoch 11/150\n8672/8672 [==============================] - 0s 23us/step - loss: 0.7196\nEpoch 12/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.7161\nEpoch 13/150\n8672/8672 [==============================] - 0s 20us/step - loss: 0.7061\nEpoch 14/150\n8672/8672 [==============================] - 0s 20us/step - loss: 0.7013\nEpoch 15/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6922\nEpoch 16/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6886\nEpoch 17/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6817\nEpoch 18/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6793\nEpoch 19/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6758\nEpoch 20/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6698\nEpoch 21/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6676\nEpoch 22/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6647\nEpoch 23/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6623\nEpoch 24/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6621\nEpoch 25/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6590\nEpoch 26/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6543\nEpoch 27/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6527\nEpoch 28/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6486\nEpoch 29/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6500\nEpoch 30/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6464\nEpoch 31/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6429\nEpoch 32/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6434\nEpoch 33/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6426\nEpoch 34/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6406\nEpoch 35/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6381\nEpoch 36/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6386\nEpoch 37/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6370\nEpoch 38/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6355\nEpoch 39/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6361\nEpoch 40/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6353\nEpoch 41/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6311\nEpoch 42/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6324\nEpoch 43/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6300\nEpoch 44/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6284\nEpoch 45/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6294\nEpoch 46/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6264\nEpoch 47/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6255\nEpoch 48/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6276\nEpoch 49/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6282\nEpoch 50/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6241\nEpoch 51/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6216\nEpoch 52/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6206\nEpoch 53/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6199\nEpoch 54/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6228\nEpoch 55/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6188\nEpoch 56/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6179\nEpoch 57/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6198\nEpoch 58/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6171\nEpoch 59/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6154\nEpoch 60/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6130\nEpoch 61/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6146\nEpoch 62/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6125\nEpoch 63/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6116\nEpoch 64/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6127\nEpoch 65/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6121\nEpoch 66/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6113\nEpoch 67/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.6094\nEpoch 68/150\n8672/8672 [==============================] - 0s 22us/step - loss: 0.6070\nEpoch 69/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6072\nEpoch 70/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6083\nEpoch 71/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6061\nEpoch 72/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6039\nEpoch 73/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6063\nEpoch 74/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.6036\nEpoch 75/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6040\nEpoch 76/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6029\nEpoch 77/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5995\nEpoch 78/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6026\nEpoch 79/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.6016\nEpoch 80/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5997\nEpoch 81/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5993\nEpoch 82/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5975\nEpoch 83/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5977\nEpoch 84/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5965\nEpoch 85/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5961\nEpoch 86/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5975\nEpoch 87/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5976\nEpoch 88/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5968\nEpoch 89/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5967\nEpoch 90/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5941\nEpoch 91/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5940\nEpoch 92/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5948\nEpoch 93/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.5927\nEpoch 94/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.5924\nEpoch 95/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5932\nEpoch 96/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.5924\nEpoch 97/150\n8672/8672 [==============================] - 0s 21us/step - loss: 0.5897\nEpoch 98/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5909\nEpoch 99/150\n8672/8672 [==============================] - 0s 20us/step - loss: 0.5920\nEpoch 100/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5892\nEpoch 101/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5909\nEpoch 102/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.5889\nEpoch 103/150\n8672/8672 [==============================] - 0s 20us/step - loss: 0.5900\nEpoch 104/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.5877\nEpoch 105/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.5898\nEpoch 106/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.5852\nEpoch 107/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5846\nEpoch 108/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5858\nEpoch 109/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5827\nEpoch 110/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5859\nEpoch 111/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5847\nEpoch 112/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5857\nEpoch 113/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5824\nEpoch 114/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5826\nEpoch 115/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5828\nEpoch 116/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.5826\nEpoch 117/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5813\nEpoch 118/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5817\nEpoch 119/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5807\nEpoch 120/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5791\nEpoch 121/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5803\nEpoch 122/150\n8672/8672 [==============================] - 0s 21us/step - loss: 0.5807\nEpoch 123/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.5790\nEpoch 124/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.5773\nEpoch 125/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5800\nEpoch 126/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.5790\nEpoch 127/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5785\nEpoch 128/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5787\nEpoch 129/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5790\nEpoch 130/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5740\nEpoch 131/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5776\nEpoch 132/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5749\nEpoch 133/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5758\nEpoch 134/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5729\nEpoch 135/150\n8672/8672 [==============================] - 0s 17us/step - loss: 0.5762\nEpoch 136/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5743\nEpoch 137/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.5699\nEpoch 138/150\n8672/8672 [==============================] - 0s 22us/step - loss: 0.5728\nEpoch 139/150\n8672/8672 [==============================] - 0s 18us/step - loss: 0.5740\nEpoch 140/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.5727\nEpoch 141/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.5706\nEpoch 142/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.5696\nEpoch 143/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.5714\nEpoch 144/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.5705\nEpoch 145/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.5713\nEpoch 146/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.5705\nEpoch 147/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.5711\nEpoch 148/150\n8672/8672 [==============================] - 0s 21us/step - loss: 0.5703\nEpoch 149/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.5716\nEpoch 150/150\n8672/8672 [==============================] - 0s 19us/step - loss: 0.5719\n"
    }
   ],
   "source": [
    "power_tr_drop_errors = evaluate_models(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "colab_type": "code",
    "id": "z2yugWWN0YRF",
    "outputId": "8e79b269-3acf-484b-afcd-ac7259654f5e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Standardization Only\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                   fold 0    fold 1    fold 2    fold 3    fold 4      mean  \\\nbaseline train   1.123358  1.121115  1.114294  1.119928  1.122722  1.120283   \nbaseline val     1.107938  1.116999  1.143970  1.121741  1.110553  1.120240   \nlinreg train     0.913938  0.915948  0.906405  0.909648  0.916653  0.912518   \nlinreg val       0.909653  0.900677  0.939456  0.929410  0.911433  0.918126   \nforestreg train  0.352948  0.348856  0.356390  0.352738  0.354742  0.353135   \nforestreg val    0.839054  0.823235  0.850745  0.842143  0.827498  0.836535   \nlinsvr train     0.931366  0.933233  0.923040  0.925438  0.930060  0.928627   \nlinsvr val       0.922163  0.920070  0.954817  0.948644  0.918581  0.932855   \nneuralnet train  0.772485  0.787028  0.759109  0.765387  0.766973  0.770196   \nneuralnet val    0.859897  0.829562  0.858548  0.844658  0.833050  0.845143   \n\n                      std  \nbaseline train   0.003609  \nbaseline val     0.014327  \nlinreg train     0.004373  \nlinreg val       0.015838  \nforestreg train  0.002814  \nforestreg val    0.011161  \nlinsvr train     0.004247  \nlinsvr val       0.017415  \nneuralnet train  0.010547  \nneuralnet val    0.014024  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fold 0</th>\n      <th>fold 1</th>\n      <th>fold 2</th>\n      <th>fold 3</th>\n      <th>fold 4</th>\n      <th>mean</th>\n      <th>std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>baseline train</th>\n      <td>1.123358</td>\n      <td>1.121115</td>\n      <td>1.114294</td>\n      <td>1.119928</td>\n      <td>1.122722</td>\n      <td>1.120283</td>\n      <td>0.003609</td>\n    </tr>\n    <tr>\n      <th>baseline val</th>\n      <td>1.107938</td>\n      <td>1.116999</td>\n      <td>1.143970</td>\n      <td>1.121741</td>\n      <td>1.110553</td>\n      <td>1.120240</td>\n      <td>0.014327</td>\n    </tr>\n    <tr>\n      <th>linreg train</th>\n      <td>0.913938</td>\n      <td>0.915948</td>\n      <td>0.906405</td>\n      <td>0.909648</td>\n      <td>0.916653</td>\n      <td>0.912518</td>\n      <td>0.004373</td>\n    </tr>\n    <tr>\n      <th>linreg val</th>\n      <td>0.909653</td>\n      <td>0.900677</td>\n      <td>0.939456</td>\n      <td>0.929410</td>\n      <td>0.911433</td>\n      <td>0.918126</td>\n      <td>0.015838</td>\n    </tr>\n    <tr>\n      <th>forestreg train</th>\n      <td>0.352948</td>\n      <td>0.348856</td>\n      <td>0.356390</td>\n      <td>0.352738</td>\n      <td>0.354742</td>\n      <td>0.353135</td>\n      <td>0.002814</td>\n    </tr>\n    <tr>\n      <th>forestreg val</th>\n      <td>0.839054</td>\n      <td>0.823235</td>\n      <td>0.850745</td>\n      <td>0.842143</td>\n      <td>0.827498</td>\n      <td>0.836535</td>\n      <td>0.011161</td>\n    </tr>\n    <tr>\n      <th>linsvr train</th>\n      <td>0.931366</td>\n      <td>0.933233</td>\n      <td>0.923040</td>\n      <td>0.925438</td>\n      <td>0.930060</td>\n      <td>0.928627</td>\n      <td>0.004247</td>\n    </tr>\n    <tr>\n      <th>linsvr val</th>\n      <td>0.922163</td>\n      <td>0.920070</td>\n      <td>0.954817</td>\n      <td>0.948644</td>\n      <td>0.918581</td>\n      <td>0.932855</td>\n      <td>0.017415</td>\n    </tr>\n    <tr>\n      <th>neuralnet train</th>\n      <td>0.772485</td>\n      <td>0.787028</td>\n      <td>0.759109</td>\n      <td>0.765387</td>\n      <td>0.766973</td>\n      <td>0.770196</td>\n      <td>0.010547</td>\n    </tr>\n    <tr>\n      <th>neuralnet val</th>\n      <td>0.859897</td>\n      <td>0.829562</td>\n      <td>0.858548</td>\n      <td>0.844658</td>\n      <td>0.833050</td>\n      <td>0.845143</td>\n      <td>0.014024</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n\nPower Transform Only\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                   fold 0    fold 1    fold 2    fold 3    fold 4      mean  \\\nbaseline train   1.123358  1.121115  1.114294  1.119928  1.122722  1.120283   \nbaseline val     1.107938  1.116999  1.143970  1.121741  1.110553  1.120240   \nlinreg train     0.893267  0.896926  0.889980  0.890549  0.894051  0.892955   \nlinreg val       0.897161  0.881527  0.910644  0.908679  0.894478  0.898498   \nforestreg train  0.351510  0.357484  0.358066  0.358803  0.352321  0.355637   \nforestreg val    0.853699  0.833393  0.842670  0.842541  0.818561  0.838173   \nlinsvr train     0.906789  0.912054  0.903541  0.903642  0.908154  0.906836   \nlinsvr val       0.908406  0.893704  0.923566  0.921239  0.904131  0.910209   \nneuralnet train  0.730743  0.734475  0.736975  0.747654  0.733245  0.736619   \nneuralnet val    0.820865  0.809628  0.809639  0.820308  0.813770  0.814842   \n\n                      std  \nbaseline train   0.003609  \nbaseline val     0.014327  \nlinreg train     0.002815  \nlinreg val       0.011802  \nforestreg train  0.003441  \nforestreg val    0.013113  \nlinsvr train     0.003536  \nlinsvr val       0.012376  \nneuralnet train  0.006565  \nneuralnet val    0.005513  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fold 0</th>\n      <th>fold 1</th>\n      <th>fold 2</th>\n      <th>fold 3</th>\n      <th>fold 4</th>\n      <th>mean</th>\n      <th>std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>baseline train</th>\n      <td>1.123358</td>\n      <td>1.121115</td>\n      <td>1.114294</td>\n      <td>1.119928</td>\n      <td>1.122722</td>\n      <td>1.120283</td>\n      <td>0.003609</td>\n    </tr>\n    <tr>\n      <th>baseline val</th>\n      <td>1.107938</td>\n      <td>1.116999</td>\n      <td>1.143970</td>\n      <td>1.121741</td>\n      <td>1.110553</td>\n      <td>1.120240</td>\n      <td>0.014327</td>\n    </tr>\n    <tr>\n      <th>linreg train</th>\n      <td>0.893267</td>\n      <td>0.896926</td>\n      <td>0.889980</td>\n      <td>0.890549</td>\n      <td>0.894051</td>\n      <td>0.892955</td>\n      <td>0.002815</td>\n    </tr>\n    <tr>\n      <th>linreg val</th>\n      <td>0.897161</td>\n      <td>0.881527</td>\n      <td>0.910644</td>\n      <td>0.908679</td>\n      <td>0.894478</td>\n      <td>0.898498</td>\n      <td>0.011802</td>\n    </tr>\n    <tr>\n      <th>forestreg train</th>\n      <td>0.351510</td>\n      <td>0.357484</td>\n      <td>0.358066</td>\n      <td>0.358803</td>\n      <td>0.352321</td>\n      <td>0.355637</td>\n      <td>0.003441</td>\n    </tr>\n    <tr>\n      <th>forestreg val</th>\n      <td>0.853699</td>\n      <td>0.833393</td>\n      <td>0.842670</td>\n      <td>0.842541</td>\n      <td>0.818561</td>\n      <td>0.838173</td>\n      <td>0.013113</td>\n    </tr>\n    <tr>\n      <th>linsvr train</th>\n      <td>0.906789</td>\n      <td>0.912054</td>\n      <td>0.903541</td>\n      <td>0.903642</td>\n      <td>0.908154</td>\n      <td>0.906836</td>\n      <td>0.003536</td>\n    </tr>\n    <tr>\n      <th>linsvr val</th>\n      <td>0.908406</td>\n      <td>0.893704</td>\n      <td>0.923566</td>\n      <td>0.921239</td>\n      <td>0.904131</td>\n      <td>0.910209</td>\n      <td>0.012376</td>\n    </tr>\n    <tr>\n      <th>neuralnet train</th>\n      <td>0.730743</td>\n      <td>0.734475</td>\n      <td>0.736975</td>\n      <td>0.747654</td>\n      <td>0.733245</td>\n      <td>0.736619</td>\n      <td>0.006565</td>\n    </tr>\n    <tr>\n      <th>neuralnet val</th>\n      <td>0.820865</td>\n      <td>0.809628</td>\n      <td>0.809639</td>\n      <td>0.820308</td>\n      <td>0.813770</td>\n      <td>0.814842</td>\n      <td>0.005513</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n\nPower Transform and Drop 10 Least Important Features\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                   fold 0    fold 1    fold 2    fold 3    fold 4      mean  \\\nbaseline train   1.123358  1.121115  1.114294  1.119928  1.122722  1.120283   \nbaseline val     1.107938  1.116999  1.143970  1.121741  1.110553  1.120240   \nlinreg train     0.895211  0.898788  0.892349  0.892274  0.896531  0.895031   \nlinreg val       0.898901  0.883642  0.910442  0.910870  0.893702  0.899511   \nforestreg train  0.353823  0.353798  0.348534  0.358351  0.353111  0.353523   \nforestreg val    0.829275  0.840292  0.832306  0.853556  0.814249  0.833936   \nlinsvr train     0.908247  0.913560  0.905552  0.905450  0.910071  0.908576   \nlinsvr val       0.909480  0.896384  0.923342  0.923145  0.904059  0.911282   \nneuralnet train  0.743611  0.755037  0.738372  0.735314  0.749691  0.744405   \nneuralnet val    0.833834  0.814097  0.828096  0.823149  0.817441  0.823323   \n\n                      std  \nbaseline train   0.003609  \nbaseline val     0.014327  \nlinreg train     0.002792  \nlinreg val       0.011559  \nforestreg train  0.003484  \nforestreg val    0.014468  \nlinsvr train     0.003395  \nlinsvr val       0.011870  \nneuralnet train  0.008072  \nneuralnet val    0.007953  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fold 0</th>\n      <th>fold 1</th>\n      <th>fold 2</th>\n      <th>fold 3</th>\n      <th>fold 4</th>\n      <th>mean</th>\n      <th>std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>baseline train</th>\n      <td>1.123358</td>\n      <td>1.121115</td>\n      <td>1.114294</td>\n      <td>1.119928</td>\n      <td>1.122722</td>\n      <td>1.120283</td>\n      <td>0.003609</td>\n    </tr>\n    <tr>\n      <th>baseline val</th>\n      <td>1.107938</td>\n      <td>1.116999</td>\n      <td>1.143970</td>\n      <td>1.121741</td>\n      <td>1.110553</td>\n      <td>1.120240</td>\n      <td>0.014327</td>\n    </tr>\n    <tr>\n      <th>linreg train</th>\n      <td>0.895211</td>\n      <td>0.898788</td>\n      <td>0.892349</td>\n      <td>0.892274</td>\n      <td>0.896531</td>\n      <td>0.895031</td>\n      <td>0.002792</td>\n    </tr>\n    <tr>\n      <th>linreg val</th>\n      <td>0.898901</td>\n      <td>0.883642</td>\n      <td>0.910442</td>\n      <td>0.910870</td>\n      <td>0.893702</td>\n      <td>0.899511</td>\n      <td>0.011559</td>\n    </tr>\n    <tr>\n      <th>forestreg train</th>\n      <td>0.353823</td>\n      <td>0.353798</td>\n      <td>0.348534</td>\n      <td>0.358351</td>\n      <td>0.353111</td>\n      <td>0.353523</td>\n      <td>0.003484</td>\n    </tr>\n    <tr>\n      <th>forestreg val</th>\n      <td>0.829275</td>\n      <td>0.840292</td>\n      <td>0.832306</td>\n      <td>0.853556</td>\n      <td>0.814249</td>\n      <td>0.833936</td>\n      <td>0.014468</td>\n    </tr>\n    <tr>\n      <th>linsvr train</th>\n      <td>0.908247</td>\n      <td>0.913560</td>\n      <td>0.905552</td>\n      <td>0.905450</td>\n      <td>0.910071</td>\n      <td>0.908576</td>\n      <td>0.003395</td>\n    </tr>\n    <tr>\n      <th>linsvr val</th>\n      <td>0.909480</td>\n      <td>0.896384</td>\n      <td>0.923342</td>\n      <td>0.923145</td>\n      <td>0.904059</td>\n      <td>0.911282</td>\n      <td>0.011870</td>\n    </tr>\n    <tr>\n      <th>neuralnet train</th>\n      <td>0.743611</td>\n      <td>0.755037</td>\n      <td>0.738372</td>\n      <td>0.735314</td>\n      <td>0.749691</td>\n      <td>0.744405</td>\n      <td>0.008072</td>\n    </tr>\n    <tr>\n      <th>neuralnet val</th>\n      <td>0.833834</td>\n      <td>0.814097</td>\n      <td>0.828096</td>\n      <td>0.823149</td>\n      <td>0.817441</td>\n      <td>0.823323</td>\n      <td>0.007953</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "print(\"Standardization Only\")\n",
    "display(std_errors)\n",
    "\n",
    "print(\"\\n\\nPower Transform Only\")\n",
    "display(power_tr_model_errors)\n",
    "\n",
    "print(\"\\n\\nPower Transform and Drop 10 Least Important Features\")\n",
    "display(power_tr_drop_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_g3GFhVmBhfP"
   },
   "source": [
    "Notes about the models so far:\n",
    "- Power transformation to numerical columns results in less error except for the random forest model where the error increases slightly\n",
    "- Removing the least important features results in slightly more error except for the random forest model where error slightly decreases\n",
    "\n",
    "Best models so far:\n",
    "- Random Forest Regressor\n",
    "- Dense Neural Network"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOyG/Y5oofr0RsEDavKQcXE",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "predicting_imdb_ratings.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}